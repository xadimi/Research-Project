{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\smart\n",
      "[nltk_data]     msi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download French stop words\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text from the CSV file\n",
    "texts = []\n",
    "with open(r'C:\\Users\\smart msi\\Downloads\\good.csv' , newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        texts.append(row[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation_and_numbers(strings):\n",
    "  # Use the string.punctuation and string.digits constants to define a set of characters to remove\n",
    "  remove_chars = set(string.punctuation + string.digits)\n",
    "\n",
    "  # Create an empty list to store the cleaned strings\n",
    "  cleaned_strings = []\n",
    "\n",
    "  # Iterate over each string in the input list\n",
    "  for s in strings:\n",
    "    # Remove the characters in the remove_chars set using a list comprehension\n",
    "    s_clean = ''.join([c for c in s if c not in remove_chars])\n",
    "\n",
    "    # Convert the string to lower case\n",
    "    s_clean = s_clean.lower()\n",
    "\n",
    "    # Add the cleaned string to the list\n",
    "    cleaned_strings.append(s_clean)\n",
    "\n",
    "  return cleaned_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "tree = ET.parse('stop_words_english.xml')\n",
    "root = tree.getroot()\n",
    "stopwordss = []\n",
    "for element in root.iter('stopword'):\n",
    "    word = element.text\n",
    "    stopwordss.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\smart\n",
      "[nltk_data]     msi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and preprocess the text\n",
    "#texts = preprocess(texts )\n",
    "\n",
    "nltk.download('stopwords')\n",
    "french_stop_words = stopwords.words('english')\n",
    "french_stop_words.extend(stopwordss)\n",
    "french_stop_words += [\"little\",\"one\",\"said\",\"day\",\"like\"]\n",
    "\n",
    "processed_texts = []\n",
    "#translated = translate_to_english(texts)\n",
    "cleaned_text = remove_punctuation_and_numbers(texts)\n",
    "\n",
    "for text in cleaned_text:\n",
    "    text = ''.join([word for word in text if word.isalpha() or word == ' '])\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in french_stop_words]\n",
    "    processed_texts.append(tokens)\n",
    "#print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of the text\n",
    "\n",
    "\n",
    "dictionary = corpora.Dictionary(processed_texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a document-term matrix\n",
    "doc_term_matrix = [dictionary.doc2bow(text) for text in processed_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LDA model\n",
    "lda_model = gensim.models.LdaModel(doc_term_matrix, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "lda_model.update(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.006*\"school\" + 0.005*\"children\" + 0.005*\"time\" + 0.005*\"go\" + 0.004*\"paris\" + 0.004*\"us\" + 0.003*\"would\" + 0.003*\"long\" + 0.003*\"two\" + 0.003*\"father\" + 0.003*\"mr\" + 0.003*\"first\" + 0.003*\"going\" + 0.003*\"away\" + 0.003*\"even\"'), (1, '0.004*\"time\" + 0.004*\"de\" + 0.004*\"children\" + 0.004*\"go\" + 0.004*\"see\" + 0.004*\"us\" + 0.003*\"dad\" + 0.003*\"big\" + 0.003*\"know\" + 0.003*\"paris\" + 0.003*\"even\" + 0.003*\"bird\" + 0.003*\"want\" + 0.003*\"could\" + 0.003*\"everyone\"'), (2, '0.006*\"old\" + 0.005*\"time\" + 0.005*\"man\" + 0.005*\"go\" + 0.004*\"would\" + 0.004*\"back\" + 0.004*\"see\" + 0.003*\"want\" + 0.003*\"mother\" + 0.003*\"know\" + 0.003*\"good\" + 0.003*\"going\" + 0.003*\"two\" + 0.003*\"well\" + 0.003*\"house\"'), (3, '0.005*\"time\" + 0.005*\"go\" + 0.004*\"back\" + 0.004*\"us\" + 0.004*\"would\" + 0.004*\"going\" + 0.004*\"know\" + 0.004*\"dad\" + 0.004*\"im\" + 0.003*\"dont\" + 0.003*\"bear\" + 0.003*\"mom\" + 0.003*\"two\" + 0.003*\"children\" + 0.003*\"school\"'), (4, '0.007*\"would\" + 0.005*\"time\" + 0.005*\"know\" + 0.004*\"dont\" + 0.004*\"even\" + 0.004*\"see\" + 0.003*\"back\" + 0.003*\"man\" + 0.003*\"could\" + 0.003*\"come\" + 0.003*\"never\" + 0.003*\"us\" + 0.003*\"eyes\" + 0.003*\"going\" + 0.003*\"night\"'), (5, '0.006*\"us\" + 0.005*\"would\" + 0.005*\"christmas\" + 0.005*\"dont\" + 0.005*\"time\" + 0.005*\"see\" + 0.004*\"go\" + 0.004*\"back\" + 0.004*\"eyes\" + 0.004*\"night\" + 0.004*\"come\" + 0.003*\"im\" + 0.003*\"plop\" + 0.003*\"away\" + 0.003*\"hand\"'), (6, '0.005*\"im\" + 0.005*\"king\" + 0.005*\"mom\" + 0.005*\"time\" + 0.004*\"even\" + 0.004*\"see\" + 0.004*\"dad\" + 0.004*\"would\" + 0.004*\"never\" + 0.004*\"go\" + 0.003*\"back\" + 0.003*\"paris\" + 0.003*\"know\" + 0.003*\"big\" + 0.003*\"dont\"'), (7, '0.005*\"good\" + 0.005*\"white\" + 0.005*\"time\" + 0.004*\"peace\" + 0.004*\"know\" + 0.004*\"children\" + 0.004*\"others\" + 0.004*\"also\" + 0.003*\"rabbit\" + 0.003*\"without\" + 0.003*\"live\" + 0.003*\"sad\" + 0.003*\"book\" + 0.003*\"us\" + 0.003*\"would\"'), (8, '0.007*\"time\" + 0.007*\"would\" + 0.004*\"old\" + 0.004*\"could\" + 0.004*\"father\" + 0.004*\"mother\" + 0.004*\"see\" + 0.003*\"back\" + 0.003*\"know\" + 0.003*\"christmas\" + 0.003*\"eyes\" + 0.003*\"looked\" + 0.003*\"two\" + 0.003*\"go\" + 0.003*\"man\"'), (9, '0.006*\"time\" + 0.005*\"back\" + 0.005*\"would\" + 0.005*\"two\" + 0.004*\"sea\" + 0.004*\"water\" + 0.003*\"long\" + 0.003*\"see\" + 0.003*\"take\" + 0.003*\"old\" + 0.003*\"away\" + 0.003*\"go\" + 0.003*\"looked\" + 0.003*\"never\" + 0.003*\"paris\"')]\n"
     ]
    }
   ],
   "source": [
    "# Extract the topics\n",
    "topics = lda_model.print_topics(num_words=15)\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.056867693), (7, 0.9373697)]\n"
     ]
    }
   ],
   "source": [
    "# Classify a new document\n",
    "new_doc = \"Children of all colors Once upon a time there was a boy named Michael who lived in a land of white boys and said, 'It is good to be white, For sugar is white and sweet, For milk is white and tasty, For snow is white and pretty. However, one day, this boy went on a trip to a country where all the children were yellow. He made a friend called Lotus Flower who said, like all yellow children: It is good to be yellow, For the sun is yellow, Just like the sunflower And the sand on the beach. The white boy continued his journey. He took a boat and stopped in a country where the children were black. He made a friend named Lumumba who said, like all black children: It is good to be black For the night is black, Just like the olives And the roads, Which take us everywhere. The white boy continued. The plane stopped in a country where all the children were red. He made a friend called Eagle Feather who said, like all red children: It's good to be red For the lights are red Like the cherries And the blood is alive. The white boy continued his walk around the world and arrived in a country where all the children were brown. He made a friend called Ali-Baba who said, like all brown children: It's good to be brown, For the earth is brown Just like the trunks of trees Just like chocolate. At the end of the journey, when Michel, the white boy, returned to his country of white children, he sang with all his heart: It's good to be white as sugar Yellow as the Sun Black as the roads Red as the fires Brown as the chocolate. And, while at school, the white children drew only white children in the white sheets, the white boy drew... big rounds with children of all colors... Luísa Ducla Soares Conceição Dinis; Fátima Lima (org.) Aventura das Letras Porto, Porto Editora, 2003 (Translation and adaptation)\"\n",
    "new_doc_tokens = nltk.word_tokenize(new_doc)\n",
    "new_doc_tokens = [token for token in new_doc_tokens if token not in french_stop_words]\n",
    "new_doc_bow = dictionary.doc2bow(new_doc_tokens)\n",
    "new_doc_topics = lda_model.get_document_topics(new_doc_bow)\n",
    "print(new_doc_topics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
